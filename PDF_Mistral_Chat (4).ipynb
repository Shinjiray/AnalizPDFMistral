{"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7371632,"sourceType":"datasetVersion","datasetId":4283127},{"sourceId":7371808,"sourceType":"datasetVersion","datasetId":4283233},{"sourceId":7456687,"sourceType":"datasetVersion","datasetId":4340414},{"sourceId":7456775,"sourceType":"datasetVersion","datasetId":4340473},{"sourceId":7457266,"sourceType":"datasetVersion","datasetId":4340813}],"dockerImageVersionId":30636,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":566.781733,"end_time":"2024-01-20T23:11:32.854988","environment_variables":{},"exception":true,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-01-20T23:02:06.073255","version":"2.4.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"06142737ef964d26800a73b15ad0fa27":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08823f7c72a94ea5b2c7747dfc39f959":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f61d5d13e25400fa2e260b0176f0b4a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"14579ad47719424ea72f9815365d242a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1597624b9cc14adeb2065f75969f3a01":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d3cdd24de67416188efb2f9905517c7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1fea7aa2382a4da88632bf636a4fabf4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"252b1e8139ff48d4b4063bf602f598d9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2d0acb7971b1471a892d9ad3246eaa5d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e32107d37494c44bdac229ea9e2236c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"326fd520cb4944d5a3ff2f5cb2a04c12":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3acd5947f0974c7883fb02f0a780d269":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2d0acb7971b1471a892d9ad3246eaa5d","placeholder":"​","style":"IPY_MODEL_1fea7aa2382a4da88632bf636a4fabf4","value":" 5.53M/5.53M [00:00&lt;00:00, 199MB/s]"}},"3fb9b8ca2db84dac8603dae350fed48c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"411e274e63d54737af06a21e42050a00":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5f84af2e2f7647f7adc2cc5a7f61405b","placeholder":"​","style":"IPY_MODEL_5c38d3f3b66348889952b9c98f0cf18e","value":" 129k/129k [00:00&lt;00:00, 807kB/s]"}},"441ef355aafe43b087e37d876297064f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d257d38eb9524da18c3aa5760cd8b5d1","placeholder":"​","style":"IPY_MODEL_78d55892f9f84411b4afb796e6972542","value":"label_encoder.txt: 100%"}},"444c88d417e8442aa78069ee068c1d36":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"44ab1605ff6c429a8829cf4aa2f691e2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4bf6fd6ab5a44aacb02f425a8af1f77c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"541ac23d3dd840a8b024863ced3042b6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"553c0649a9ca49d8b6dcdd25ef83f4e5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_441ef355aafe43b087e37d876297064f","IPY_MODEL_c6cd6f51b2864a138a51b22df027c4da","IPY_MODEL_411e274e63d54737af06a21e42050a00"],"layout":"IPY_MODEL_dcd586b5cb024384a3e6c8245d659b07"}},"5c38d3f3b66348889952b9c98f0cf18e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5f84af2e2f7647f7adc2cc5a7f61405b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64371f096c904877870e4ec7f2095286":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"67b52b63feb843db9904865a45840e24":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_444c88d417e8442aa78069ee068c1d36","max":5534328,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8bcd59687e4a422296124017db700c6d","value":5534328}},"68e04dd5b21f4d0dbc4afa9452b5e2de":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_93f0a30735b14c27b800dba01b2094e4","IPY_MODEL_67b52b63feb843db9904865a45840e24","IPY_MODEL_3acd5947f0974c7883fb02f0a780d269"],"layout":"IPY_MODEL_6d2b0c5d58ae4d70b11f85a6653e9a2e"}},"6d2b0c5d58ae4d70b11f85a6653e9a2e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"71927307af8441049c37019d025557d3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"71b7cfc0f59c4229ae9777c43c47c103":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"730e592641a645a89172f9dd40160601":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"78d55892f9f84411b4afb796e6972542":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7ca225d533604e5db4259057867c9423":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_71b7cfc0f59c4229ae9777c43c47c103","placeholder":"​","style":"IPY_MODEL_beb30bd99ca941308ad4dbc1b9ba692d","value":"mean_var_norm_emb.ckpt: 100%"}},"8226ffabe8094f608ac57fa2ef36c63a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"87946563143b4186996d0244c63a8f1b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0f61d5d13e25400fa2e260b0176f0b4a","placeholder":"​","style":"IPY_MODEL_f2749bea84b24588a0ef2322c18ab3d8","value":"hyperparams.yaml: 100%"}},"8bcd59687e4a422296124017db700c6d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8bdce963570549488618b67930853944":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_06142737ef964d26800a73b15ad0fa27","placeholder":"​","style":"IPY_MODEL_64371f096c904877870e4ec7f2095286","value":" 1.92k/1.92k [00:00&lt;00:00, 136kB/s]"}},"92c613743c124974950f5967905ff826":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"93f0a30735b14c27b800dba01b2094e4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4bf6fd6ab5a44aacb02f425a8af1f77c","placeholder":"​","style":"IPY_MODEL_2e32107d37494c44bdac229ea9e2236c","value":"classifier.ckpt: 100%"}},"a5893239cd5a4cef878cbfc4ac233064":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b52b466d04c3413b81b0011f16df7029":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"baad7e2bbee448739c8c846a5f5f9c0f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e744e02e37854e70aaef23bb188d0d43","max":83316686,"min":0,"orientation":"horizontal","style":"IPY_MODEL_92c613743c124974950f5967905ff826","value":83316686}},"bb1eca7cbd91440d904e0020a1a5d818":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_87946563143b4186996d0244c63a8f1b","IPY_MODEL_ce35d9bb3ada4ed7b694c09d12e0de20","IPY_MODEL_8bdce963570549488618b67930853944"],"layout":"IPY_MODEL_08823f7c72a94ea5b2c7747dfc39f959"}},"beb30bd99ca941308ad4dbc1b9ba692d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bf5c0bbf2b904a058d5d58b32ddd6af3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d3cdd24de67416188efb2f9905517c7","placeholder":"​","style":"IPY_MODEL_71927307af8441049c37019d025557d3","value":" 1.92k/1.92k [00:00&lt;00:00, 146kB/s]"}},"c4d488287984435388a01fc6ffdb3dbf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_44ab1605ff6c429a8829cf4aa2f691e2","placeholder":"​","style":"IPY_MODEL_252b1e8139ff48d4b4063bf602f598d9","value":"embedding_model.ckpt: 100%"}},"c6cd6f51b2864a138a51b22df027c4da":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_730e592641a645a89172f9dd40160601","max":128619,"min":0,"orientation":"horizontal","style":"IPY_MODEL_326fd520cb4944d5a3ff2f5cb2a04c12","value":128619}},"ce35d9bb3ada4ed7b694c09d12e0de20":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a5893239cd5a4cef878cbfc4ac233064","max":1920,"min":0,"orientation":"horizontal","style":"IPY_MODEL_541ac23d3dd840a8b024863ced3042b6","value":1920}},"cffc76f22c7647839feca02841584745":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7ca225d533604e5db4259057867c9423","IPY_MODEL_d6a871594f084d3f9583cf9ad6facc51","IPY_MODEL_bf5c0bbf2b904a058d5d58b32ddd6af3"],"layout":"IPY_MODEL_14579ad47719424ea72f9815365d242a"}},"d257d38eb9524da18c3aa5760cd8b5d1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6a871594f084d3f9583cf9ad6facc51":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1597624b9cc14adeb2065f75969f3a01","max":1921,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8226ffabe8094f608ac57fa2ef36c63a","value":1921}},"dcd586b5cb024384a3e6c8245d659b07":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e287ea98ad3f41cd80b8804504a89d11":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e744e02e37854e70aaef23bb188d0d43":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea971ca1a3b249a39c76a75ed8bec396":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c4d488287984435388a01fc6ffdb3dbf","IPY_MODEL_baad7e2bbee448739c8c846a5f5f9c0f","IPY_MODEL_fb80501e13f3403397575583d8993f7f"],"layout":"IPY_MODEL_e287ea98ad3f41cd80b8804504a89d11"}},"f2749bea84b24588a0ef2322c18ab3d8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fb80501e13f3403397575583d8993f7f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3fb9b8ca2db84dac8603dae350fed48c","placeholder":"​","style":"IPY_MODEL_b52b466d04c3413b81b0011f16df7029","value":" 83.3M/83.3M [00:00&lt;00:00, 228MB/s]"}}},"version_major":2,"version_minor":0}}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --upgrade pip -q\n!pip install --upgrade kaggle\n","metadata":{"id":"yj52wI-Y8V0V","papermill":{"duration":38.251664,"end_time":"2024-01-20T23:02:47.675652","exception":false,"start_time":"2024-01-20T23:02:09.423988","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-22T15:32:37.132454Z","iopub.execute_input":"2024-01-22T15:32:37.133223Z","iopub.status.idle":"2024-01-22T15:33:01.662004Z","shell.execute_reply.started":"2024-01-22T15:32:37.133184Z","shell.execute_reply":"2024-01-22T15:33:01.660863Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Requirement already satisfied: kaggle in /opt/conda/lib/python3.10/site-packages (1.6.3)\nRequirement already satisfied: six>=1.10 in /opt/conda/lib/python3.10/site-packages (from kaggle) (1.16.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from kaggle) (2023.11.17)\nRequirement already satisfied: python-dateutil in /opt/conda/lib/python3.10/site-packages (from kaggle) (2.8.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from kaggle) (2.31.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from kaggle) (4.66.1)\nRequirement already satisfied: python-slugify in /opt/conda/lib/python3.10/site-packages (from kaggle) (8.0.1)\nRequirement already satisfied: urllib3 in /opt/conda/lib/python3.10/site-packages (from kaggle) (1.26.15)\nRequirement already satisfied: bleach in /opt/conda/lib/python3.10/site-packages (from kaggle) (6.0.0)\nRequirement already satisfied: webencodings in /opt/conda/lib/python3.10/site-packages (from bleach->kaggle) (0.5.1)\nRequirement already satisfied: text-unidecode>=1.3 in /opt/conda/lib/python3.10/site-packages (from python-slugify->kaggle) (1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->kaggle) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->kaggle) (3.4)\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install numpy==1.23.0","metadata":{"papermill":{"duration":15.985703,"end_time":"2024-01-20T23:03:03.671656","exception":false,"start_time":"2024-01-20T23:02:47.685953","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-22T15:33:03.111191Z","iopub.execute_input":"2024-01-22T15:33:03.111927Z","iopub.status.idle":"2024-01-22T15:33:15.047477Z","shell.execute_reply.started":"2024-01-22T15:33:03.111895Z","shell.execute_reply":"2024-01-22T15:33:15.046458Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Requirement already satisfied: numpy==1.23.0 in /opt/conda/lib/python3.10/site-packages (1.23.0)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#Запускаем","metadata":{"id":"jhdt_UNvGQMj","papermill":{"duration":0.010504,"end_time":"2024-01-20T23:03:03.693354","exception":false,"start_time":"2024-01-20T23:03:03.682850","status":"completed"},"tags":[]}},{"cell_type":"code","source":"!pip install pydantic==1.8.1","metadata":{"execution":{"iopub.status.busy":"2024-01-22T15:33:23.919333Z","iopub.execute_input":"2024-01-22T15:33:23.920139Z","iopub.status.idle":"2024-01-22T15:33:35.883477Z","shell.execute_reply.started":"2024-01-22T15:33:23.920108Z","shell.execute_reply":"2024-01-22T15:33:35.882279Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pydantic==1.8.1 in /opt/conda/lib/python3.10/site-packages (1.8.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from pydantic==1.8.1) (4.5.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"\n!pip install -U openai -q\n!pip install pytelegrambotapi -q\n!pip install -U deep-translator -q\n!pip install langchain tiktoken -q\n!pip install pydub -q\n#!pip install git+https://github.com/openai/whisper.git -q\n!sudo apt install ffmpeg","metadata":{"papermill":{"duration":91.671836,"end_time":"2024-01-20T23:04:35.376010","exception":false,"start_time":"2024-01-20T23:03:03.704174","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-22T15:35:43.344363Z","iopub.execute_input":"2024-01-22T15:35:43.345033Z","iopub.status.idle":"2024-01-22T15:36:49.707137Z","shell.execute_reply.started":"2024-01-22T15:35:43.345002Z","shell.execute_reply":"2024-01-22T15:36:49.706082Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 11.0.0 which is incompatible.\nchex 0.1.85 requires numpy>=1.24.1, but you have numpy 1.23.0 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.1 which is incompatible.\ncuml 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.1 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.1 which is incompatible.\ndask-cudf 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.1 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\njupyterlab 4.0.10 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.0.1 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\npymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.23.0 which is incompatible.\npymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.11.4 which is incompatible.\ntensorflow 2.13.0 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.9.0 which is incompatible.\ntensorflow-probability 0.21.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\nydata-profiling 4.5.1 requires pydantic<2,>=1.8.1, but you have pydantic 2.5.3 which is incompatible.\u001b[0m\u001b[31m\nReading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n0 upgraded, 0 newly installed, 0 to remove and 81 not upgraded.\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install langchain\n!pip install torch\n!pip install sentence_transformers\n!pip install faiss-cpu\n!pip install huggingface-hub\n!pip install pypdf\n!pip -q install accelerate\n!pip install llama-cpp-python\n!pip -q install git+https://github.com/huggingface/transformers\n!pip install fpdf\n","metadata":{"id":"kz_gWlZFw9Ve","outputId":"95e51ae9-49e6-4918-a6fa-9f1460a2d8c3","papermill":{"duration":219.665511,"end_time":"2024-01-20T23:08:15.057486","exception":false,"start_time":"2024-01-20T23:04:35.391975","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-22T15:36:58.591318Z","iopub.execute_input":"2024-01-22T15:36:58.592391Z","iopub.status.idle":"2024-01-22T15:39:22.365988Z","shell.execute_reply.started":"2024-01-22T15:36:58.592353Z","shell.execute_reply":"2024-01-22T15:39:22.364665Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Requirement already satisfied: langchain in /opt/conda/lib/python3.10/site-packages (0.1.1)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.1)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.20)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.8.5)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.6.3)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.33)\nRequirement already satisfied: langchain-community<0.1,>=0.0.13 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.0.13)\nRequirement already satisfied: langchain-core<0.2,>=0.1.9 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.1.13)\nRequirement already satisfied: langsmith<0.1.0,>=0.0.77 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.0.83)\nRequirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.23.0)\nRequirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.5.3)\nRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.31.0)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.2.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.2)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.0)\nRequirement already satisfied: anyio<5,>=3 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.2,>=0.1.9->langchain) (3.7.1)\nRequirement already satisfied: packaging<24.0,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.2,>=0.1.9->langchain) (23.2)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.14.6)\nRequirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.7.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2023.11.17)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\nRequirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.9->langchain) (1.3.0)\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.9->langchain) (1.1.3)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.0.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.7.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nRequirement already satisfied: sentence_transformers in /opt/conda/lib/python3.10/site-packages (2.2.2)\nRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.38.0.dev0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.66.1)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (2.0.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (0.15.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.23.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.11.4)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (3.2.4)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (0.1.99)\nRequirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (0.20.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.12.2)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.12.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.31.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.7.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2023.8.8)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.15.0)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.4.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk->sentence_transformers) (1.16.0)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (3.2.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->sentence_transformers) (9.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2023.11.17)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\nRequirement already satisfied: faiss-cpu in /opt/conda/lib/python3.10/site-packages (1.7.4)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (0.20.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub) (3.12.2)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub) (2023.12.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub) (4.66.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub) (4.7.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub) (23.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub) (2023.11.17)\nRequirement already satisfied: pypdf in /opt/conda/lib/python3.10/site-packages (3.17.4)\nRequirement already satisfied: llama-cpp-python in /opt/conda/lib/python3.10/site-packages (0.2.32)\nRequirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/lib/python3.10/site-packages (from llama-cpp-python) (4.7.1)\nRequirement already satisfied: numpy>=1.20.0 in /opt/conda/lib/python3.10/site-packages (from llama-cpp-python) (1.23.0)\nRequirement already satisfied: diskcache>=5.6.1 in /opt/conda/lib/python3.10/site-packages (from llama-cpp-python) (5.6.3)\nRequirement already satisfied: jinja2>=2.11.3 in /opt/conda/lib/python3.10/site-packages (from llama-cpp-python) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.3)\nRequirement already satisfied: fpdf in /opt/conda/lib/python3.10/site-packages (1.7.2)\n","output_type":"stream"}]},{"cell_type":"code","source":"from openai import OpenAI\nimport telebot\nimport matplotlib.pyplot as plt\nfrom deep_translator import GoogleTranslator\nfrom PIL import Image\nimport io\nimport base64\nfrom langchain.chat_models import ChatOpenAI\nimport os","metadata":{"id":"UXDGLPd3s13E","papermill":{"duration":1.55068,"end_time":"2024-01-20T23:08:19.665064","exception":false,"start_time":"2024-01-20T23:08:18.114384","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-22T15:39:43.135828Z","iopub.execute_input":"2024-01-22T15:39:43.136503Z","iopub.status.idle":"2024-01-22T15:39:43.141289Z","shell.execute_reply.started":"2024-01-22T15:39:43.136468Z","shell.execute_reply":"2024-01-22T15:39:43.140311Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"#Запускаем ниже остальное","metadata":{"execution":{"iopub.execute_input":"2024-01-20T23:08:19.717190Z","iopub.status.busy":"2024-01-20T23:08:19.716624Z","iopub.status.idle":"2024-01-20T23:08:19.720957Z","shell.execute_reply":"2024-01-20T23:08:19.720107Z"},"id":"bT3hnw0g4P92","papermill":{"duration":0.032417,"end_time":"2024-01-20T23:08:19.722848","exception":false,"start_time":"2024-01-20T23:08:19.690431","status":"completed"},"tags":[]},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from langchain.chains import RetrievalQA\nfrom langchain.embeddings import HuggingFaceEmbeddings\nfrom langchain.llms import LlamaCpp\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.vectorstores import FAISS\nfrom langchain.document_loaders import PyPDFDirectoryLoader","metadata":{"id":"oaJJtHLRw_cS","papermill":{"duration":1.70255,"end_time":"2024-01-20T23:08:21.450133","exception":false,"start_time":"2024-01-20T23:08:19.747583","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-22T15:39:54.279615Z","iopub.execute_input":"2024-01-22T15:39:54.280487Z","iopub.status.idle":"2024-01-22T15:39:55.920539Z","shell.execute_reply.started":"2024-01-22T15:39:54.280455Z","shell.execute_reply":"2024-01-22T15:39:55.919594Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"id":"NiFR9dtOxSEo","papermill":{"duration":0.024807,"end_time":"2024-01-20T23:08:21.500452","exception":false,"start_time":"2024-01-20T23:08:21.475645","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"id":"wTlXMFevfxw2","outputId":"04374cef-233b-4d67-f764-be4c7d8500d9","papermill":{"duration":0.025684,"end_time":"2024-01-20T23:08:21.551298","exception":false,"start_time":"2024-01-20T23:08:21.525614","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Нужно скачать файл модели вот отсюда https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/tree/main , подойдет любая с форматом guff/ но чем больше размер тем дольше обработка. В ячейки ниже при параметрах  n_ctx=4096 и\n\n```\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size=5000, chunk_overlap=100)\ntext_chunks = text_splitter.split_documents(data)\n```\n\n\n средняя время обработки, например  уголовного кодекса 4-7 минут(300 страниц) одного вопроса, но маленькие 1-5 страниц (пол минуты - 1.5минуты), но любой первый вопрос он будет обрабатывать медленее чем обычно\n\n1.   А при n_ctx=4096, chunk_size=10000, chunk_overlap=2000 больше часа. Я остановил спустя 1:12/ И не знаю за сколько он справится. Как интересный пример, оставлю на ночь и посмотрю. Но это уже не в проекте.\n\n","metadata":{"id":"1lspiUDE48DR","papermill":{"duration":0.0249,"end_time":"2024-01-20T23:08:21.601329","exception":false,"start_time":"2024-01-20T23:08:21.576429","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#Import Model\nllm = LlamaCpp(\n    streaming = True,\n    model_path=\"/kaggle/input/mistral4gb/mistral-7b-instruct-v0.1.Q4_K_S.gguf\",\n    temperature=0.75,\n    top_p=1,\n    verbose=True,\n    n_ctx=8096,\n\n)","metadata":{"id":"8bkS3EkEwl5s","outputId":"64df9ce7-96e6-4d84-cfd9-b4bdb02fedad","papermill":{"duration":26.387734,"end_time":"2024-01-20T23:08:48.014421","exception":false,"start_time":"2024-01-20T23:08:21.626687","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-22T15:40:01.808443Z","iopub.execute_input":"2024-01-22T15:40:01.808820Z","iopub.status.idle":"2024-01-22T15:40:53.419443Z","shell.execute_reply.started":"2024-01-22T15:40:01.808792Z","shell.execute_reply":"2024-01-22T15:40:53.418478Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"llama_model_loader: loaded meta data with 20 key-value pairs and 291 tensors from /kaggle/input/mistral4gb/mistral-7b-instruct-v0.1.Q4_K_S.gguf (version GGUF V2)\nllama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\nllama_model_loader: - kv   0:                       general.architecture str              = llama\nllama_model_loader: - kv   1:                               general.name str              = mistralai_mistral-7b-instruct-v0.1\nllama_model_loader: - kv   2:                       llama.context_length u32              = 32768\nllama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\nllama_model_loader: - kv   4:                          llama.block_count u32              = 32\nllama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\nllama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\nllama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\nllama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\nllama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\nllama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\nllama_model_loader: - kv  11:                          general.file_type u32              = 14\nllama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\nllama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\nllama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\nllama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\nllama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\nllama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\nllama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\nllama_model_loader: - kv  19:               general.quantization_version u32              = 2\nllama_model_loader: - type  f32:   65 tensors\nllama_model_loader: - type q4_K:  217 tensors\nllama_model_loader: - type q5_K:    8 tensors\nllama_model_loader: - type q6_K:    1 tensors\nllm_load_vocab: special tokens definition check successful ( 259/32000 ).\nllm_load_print_meta: format           = GGUF V2\nllm_load_print_meta: arch             = llama\nllm_load_print_meta: vocab type       = SPM\nllm_load_print_meta: n_vocab          = 32000\nllm_load_print_meta: n_merges         = 0\nllm_load_print_meta: n_ctx_train      = 32768\nllm_load_print_meta: n_embd           = 4096\nllm_load_print_meta: n_head           = 32\nllm_load_print_meta: n_head_kv        = 8\nllm_load_print_meta: n_layer          = 32\nllm_load_print_meta: n_rot            = 128\nllm_load_print_meta: n_embd_head_k    = 128\nllm_load_print_meta: n_embd_head_v    = 128\nllm_load_print_meta: n_gqa            = 4\nllm_load_print_meta: n_embd_k_gqa     = 1024\nllm_load_print_meta: n_embd_v_gqa     = 1024\nllm_load_print_meta: f_norm_eps       = 0.0e+00\nllm_load_print_meta: f_norm_rms_eps   = 1.0e-05\nllm_load_print_meta: f_clamp_kqv      = 0.0e+00\nllm_load_print_meta: f_max_alibi_bias = 0.0e+00\nllm_load_print_meta: n_ff             = 14336\nllm_load_print_meta: n_expert         = 0\nllm_load_print_meta: n_expert_used    = 0\nllm_load_print_meta: rope scaling     = linear\nllm_load_print_meta: freq_base_train  = 10000.0\nllm_load_print_meta: freq_scale_train = 1\nllm_load_print_meta: n_yarn_orig_ctx  = 32768\nllm_load_print_meta: rope_finetuned   = unknown\nllm_load_print_meta: model type       = 7B\nllm_load_print_meta: model ftype      = Q4_K - Small\nllm_load_print_meta: model params     = 7.24 B\nllm_load_print_meta: model size       = 3.86 GiB (4.57 BPW) \nllm_load_print_meta: general.name     = mistralai_mistral-7b-instruct-v0.1\nllm_load_print_meta: BOS token        = 1 '<s>'\nllm_load_print_meta: EOS token        = 2 '</s>'\nllm_load_print_meta: UNK token        = 0 '<unk>'\nllm_load_print_meta: LF token         = 13 '<0x0A>'\nllm_load_tensors: ggml ctx size =    0.11 MiB\nllm_load_tensors: offloading 0 repeating layers to GPU\nllm_load_tensors: offloaded 0/33 layers to GPU\nllm_load_tensors:        CPU buffer size =  3947.87 MiB\n..................................................................................................\nllama_new_context_with_model: n_ctx      = 8096\nllama_new_context_with_model: freq_base  = 10000.0\nllama_new_context_with_model: freq_scale = 1\nllama_kv_cache_init:        CPU KV buffer size =  1012.00 MiB\nllama_new_context_with_model: KV self size  = 1012.00 MiB, K (f16):  506.00 MiB, V (f16):  506.00 MiB\nllama_new_context_with_model: graph splits (measure): 1\nllama_new_context_with_model:        CPU compute buffer size =     8.59 MiB\nAVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | \nModel metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.rope.freq_base': '10000.000000', 'llama.context_length': '32768', 'general.name': 'mistralai_mistral-7b-instruct-v0.1', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.bos_token_id': '1', 'llama.attention.head_count': '32', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '14'}\n","output_type":"stream"}]},{"cell_type":"code","source":"print(llm)","metadata":{"id":"ptiFa4D5C89E","outputId":"a7bd3f8d-aaa8-49f2-dbcc-795ffcefccf8","papermill":{"duration":0.034695,"end_time":"2024-01-20T23:08:48.075219","exception":false,"start_time":"2024-01-20T23:08:48.040524","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-22T15:41:05.803294Z","iopub.execute_input":"2024-01-22T15:41:05.804169Z","iopub.status.idle":"2024-01-22T15:41:05.808622Z","shell.execute_reply.started":"2024-01-22T15:41:05.804135Z","shell.execute_reply":"2024-01-22T15:41:05.807722Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"\u001b[1mLlamaCpp\u001b[0m\nParams: {'model_path': '/kaggle/input/mistral4gb/mistral-7b-instruct-v0.1.Q4_K_S.gguf', 'suffix': None, 'max_tokens': 256, 'temperature': 0.75, 'top_p': 1.0, 'logprobs': None, 'echo': False, 'stop_sequences': [], 'repeat_penalty': 1.1, 'top_k': 40}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#Установка библиотек для распознования голосов","metadata":{"id":"eYDOiWMBD9NH","papermill":{"duration":0.025813,"end_time":"2024-01-20T23:08:48.126889","exception":false,"start_time":"2024-01-20T23:08:48.101076","status":"completed"},"tags":[]}},{"cell_type":"code","source":"!pip install -q git+https://github.com/openai/whisper.git > /dev/null\n!pip install -q git+https://github.com/pyannote/pyannote-audio > /dev/null\n\nimport whisper\nimport datetime\n\nimport subprocess\n\nimport torch\nimport pyannote.audio\nfrom pyannote.audio.pipelines.speaker_verification import PretrainedSpeakerEmbedding\nembedding_model = PretrainedSpeakerEmbedding(\n    \"speechbrain/spkrec-ecapa-voxceleb\",\n    device=torch.device(\"cuda\"))\n\nfrom pyannote.audio import Audio\nfrom pyannote.core import Segment\n\nimport wave\nimport contextlib\n\nfrom sklearn.cluster import AgglomerativeClustering\nimport numpy as np\n\nfrom fpdf import FPDF\n!pip install reportlab\n\nfrom reportlab.lib.pagesizes import letter\nfrom reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\nfrom reportlab.platypus import SimpleDocTemplate, Paragraph\n\n# Регистрация пользовательского шрифта\nfrom reportlab.pdfbase import pdfmetrics\nfrom reportlab.pdfbase.ttfonts import TTFont","metadata":{"id":"KpOmTraS_yy3","outputId":"06a196f5-ca6c-4d75-f957-0405541d388d","papermill":{"duration":97.820058,"end_time":"2024-01-20T23:10:25.973098","exception":false,"start_time":"2024-01-20T23:08:48.153040","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-22T15:41:08.703919Z","iopub.execute_input":"2024-01-22T15:41:08.704323Z","iopub.status.idle":"2024-01-22T15:43:14.127530Z","shell.execute_reply.started":"2024-01-22T15:41:08.704282Z","shell.execute_reply":"2024-01-22T15:43:14.126467Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"hyperparams.yaml:   0%|          | 0.00/1.92k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79baab244084483c957164211580072d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"embedding_model.ckpt:   0%|          | 0.00/83.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"741f8c5b601f473ea755a8db65b408f6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"mean_var_norm_emb.ckpt:   0%|          | 0.00/1.92k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0e1ef0a9e1e4812a7079c01dcf2a2d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"classifier.ckpt:   0%|          | 0.00/5.53M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5a27ff395ce4bd1b5a3852ad3e0473f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"label_encoder.txt:   0%|          | 0.00/129k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"abd2facf35ed4949b5d7f5fdc756cb6b"}},"metadata":{}},{"name":"stdout","text":"Collecting reportlab\n  Downloading reportlab-4.0.9-py3-none-any.whl.metadata (1.4 kB)\nRequirement already satisfied: pillow>=9.0.0 in /opt/conda/lib/python3.10/site-packages (from reportlab) (9.5.0)\nCollecting chardet (from reportlab)\n  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\nDownloading reportlab-4.0.9-py3-none-any.whl (1.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading chardet-5.2.0-py3-none-any.whl (199 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.4/199.4 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: chardet, reportlab\nSuccessfully installed chardet-5.2.0 reportlab-4.0.9\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#Распознаем голоса и составляем диалог в формате txt и его превращаем в pdf и сохраняем в Data так же нужно установить шрифт, для корректного отображеня PDF файла. Готовый PDF будет на гит хабе, чтобы не занимать память графического процессора в колабе,можно этот шаг пропустить предварительно загрузив в data PDF файлы, который нам понадобиться при анализе текста, в гит хабе будут готовый обработанный диалог в PDF и один большой PDF файл, кодекс РФ","metadata":{"id":"kAlaUlLdEVJt","papermill":{"duration":0.026746,"end_time":"2024-01-20T23:10:26.027445","exception":false,"start_time":"2024-01-20T23:10:26.000699","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"##Дальше снизу идет код по обработке аудиофайла","metadata":{"id":"oz8l47q79ClX","papermill":{"duration":0.026794,"end_time":"2024-01-20T23:10:26.081383","exception":false,"start_time":"2024-01-20T23:10:26.054589","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# model_size: в зависимости от выбранной вами версии 'tiny', 'base', 'small', 'medium', 'large', мы получим разное качество распознавания","metadata":{"id":"adQx6iI7D3n_","papermill":{"duration":0.027345,"end_time":"2024-01-20T23:10:26.135641","exception":false,"start_time":"2024-01-20T23:10:26.108296","status":"completed"},"tags":[]}},{"cell_type":"code","source":"num_speakers = 2 #@param {type:\"integer\"}\n\nlanguage = 'any' #@param ['any', 'English']\n\nmodel_size = 'large' #@param ['tiny', 'base', 'small', 'medium', 'large']\n\n\nmodel_name = model_size\nif language == 'English' and model_size != 'large':\n  model_name += '.en'\n\nmodel = whisper.load_model(model_size)","metadata":{"id":"jp4-uvNA_x2b","papermill":{"duration":62.267452,"end_time":"2024-01-20T23:11:28.430298","exception":false,"start_time":"2024-01-20T23:10:26.162846","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-22T15:43:14.129625Z","iopub.execute_input":"2024-01-22T15:43:14.130522Z","iopub.status.idle":"2024-01-22T15:44:27.445078Z","shell.execute_reply.started":"2024-01-22T15:43:14.130485Z","shell.execute_reply":"2024-01-22T15:44:27.444203Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"100%|█████████████████████████████████████| 2.88G/2.88G [00:45<00:00, 67.8MiB/s]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#Загружаем аудио и обрабатываем\nможем этот шаг пропустить,и загрузить вручную. Так памяти будет больше для анализа","metadata":{"id":"37bnpUlMdW36","papermill":{"duration":0.051587,"end_time":"2024-01-20T23:11:28.533025","exception":false,"start_time":"2024-01-20T23:11:28.481438","status":"completed"},"tags":[]}},{"cell_type":"code","source":"pip install dejavu-fonts-ttf","metadata":{"execution":{"iopub.status.busy":"2024-01-22T15:58:55.914040Z","iopub.execute_input":"2024-01-22T15:58:55.914965Z","iopub.status.idle":"2024-01-22T15:58:58.220231Z","shell.execute_reply.started":"2024-01-22T15:58:55.914931Z","shell.execute_reply":"2024-01-22T15:58:58.219045Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: Could not find a version that satisfies the requirement dejavu-fonts-ttf (from versions: none)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for dejavu-fonts-ttf\u001b[0m\u001b[31m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"# upload audio file\n\npath = '/kaggle/input/testwav/AUD-20231127-WA0003'\nif path[-3:] != 'wav':\n  subprocess.call(['ffmpeg', '-i', path, 'audio.wav', '-y'])\n  path = 'audio.wav'\n\nresult = model.transcribe(path)\nsegments = result[\"segments\"]\nwith contextlib.closing(wave.open(path,'r')) as f:\n  frames = f.getnframes()\n  rate = f.getframerate()\n  duration = frames / float(rate)\naudio = Audio()\n\ndef segment_embedding(segment):\n  start = segment[\"start\"]\n  # Whisper overshoots the end timestamp in the last segment\n  end = min(duration, segment[\"end\"])\n  clip = Segment(start, end)\n  waveform, sample_rate = audio.crop(path, clip)\n  return embedding_model(waveform[None])\n\nembeddings1 = np.zeros(shape=(len(segments), 192))\nfor i, segment in enumerate(segments):\n  embeddings1[i] = segment_embedding(segment)\n\nembeddings1 = np.nan_to_num(embeddings1)\n\nclustering = AgglomerativeClustering(num_speakers).fit(embeddings1)\nlabels = clustering.labels_\nfor i in range(len(segments)):\n  segments[i][\"speaker\"] = 'SPEAKER ' + str(labels[i] + 1)\n\ndef time(secs):\n  return datetime.timedelta(seconds=round(secs))\n\nf = open(\"transcript.txt\", \"w\")\n\nfor (i, segment) in enumerate(segments):\n  if i == 0 or segments[i - 1][\"speaker\"] != segment[\"speaker\"]:\n    f.write(\"\\n\" + segment[\"speaker\"] + ' ' + str(time(segment[\"start\"])) + '\\n')\n  f.write(segment[\"text\"][1:] + ' ')\nf.close()\n\n\n\n##КОнвертируем в PDF##################################################\n\n#Установи шриф(в гит хабе естғ фаЙл)\nfont_path = '/kaggle/input/dejfont/DejaVuSans.ttf'\npdfmetrics.registerFont(TTFont(\"DejaVu\", font_path))\n\n# Создание стилей для абзацев\nstyles = getSampleStyleSheet()\ncustom_style = ParagraphStyle(\n    'CustomStyle',\n    parent=styles['Normal'],\n    fontName='DejaVu',\n    fontSize=12,\n)\n\ndef create_pdf(input_file, output_file):\n    # Создание PDF-документа\n    pdf = SimpleDocTemplate(output_file, pagesize=letter)\n\n    # Открытие текстового файла в режиме чтения\n    with open(input_file, \"r\", encoding='utf-8') as file:\n        # Сборка Paragraphs для вставки в документ\n        paragraphs = []\n        for line in file:\n            paragraphs.append(Paragraph(line, custom_style))\n\n    # Добавление Paragraphs в документ\n    pdf.build(paragraphs)\n\n# Конвертация текстового файла в PDF\ninput_file = \"transcript.txt\"\noutput_file = \"/kaggle/working/transcript.pdf\"\ncreate_pdf(input_file, output_file)\n\n","metadata":{"id":"7YaWvMfH_7Mn","outputId":"202152fc-c510-4a68-8e09-1da336f64bfa","papermill":{"duration":1.014032,"end_time":"2024-01-20T23:11:29.597993","exception":true,"start_time":"2024-01-20T23:11:28.583961","status":"failed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-22T16:04:58.312410Z","iopub.execute_input":"2024-01-22T16:04:58.313361Z","iopub.status.idle":"2024-01-22T16:05:21.745168Z","shell.execute_reply.started":"2024-01-22T16:04:58.313324Z","shell.execute_reply":"2024-01-22T16:05:21.744393Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n  libavutil      56. 70.100 / 56. 70.100\n  libavcodec     58.134.100 / 58.134.100\n  libavformat    58. 76.100 / 58. 76.100\n  libavdevice    58. 13.100 / 58. 13.100\n  libavfilter     7.110.100 /  7.110.100\n  libswscale      5.  9.100 /  5.  9.100\n  libswresample   3.  9.100 /  3.  9.100\n  libpostproc    55.  9.100 / 55.  9.100\n[mp3 @ 0x56d6f93af540] Estimating duration from bitrate, this may be inaccurate\nInput #0, mp3, from '/kaggle/input/testwav/AUD-20231127-WA0003':\n  Duration: 00:01:18.07, start: 0.000000, bitrate: 23 kb/s\n  Stream #0:0: Audio: mp3, 16000 Hz, mono, fltp, 24 kb/s\nStream mapping:\n  Stream #0:0 -> #0:0 (mp3 (mp3float) -> pcm_s16le (native))\nPress [q] to stop, [?] for help\nOutput #0, wav, to 'audio.wav':\n  Metadata:\n    ISFT            : Lavf58.76.100\n  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n    Metadata:\n      encoder         : Lavc58.134.100 pcm_s16le\nsize=    2440kB time=00:01:18.04 bitrate= 256.1kbits/s speed= 810x    \nvideo:0kB audio:2440kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.003122%\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"id":"THsrYzXJ9N4A","papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Отсөда начинает Анализ текста с PDF фалов, которые лежат в папке Data :/content/sample_data/Data","metadata":{"id":"5npv-YWf9OuU","papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]}},{"cell_type":"markdown","source":"#Работ по тексту, все файлы PDF в папке Data(их может быть несколько) обрабатываются и по этим файлам бот находит ответы.","metadata":{"id":"UrNMSrbgJ40z","papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"loader = PyPDFDirectoryLoader(\"/kaggle/input/fakedata/\")\ndata = loader.load()\n\nembeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n\n#Step 05: Split the Extracted Data into Text Chunks\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size=5000, chunk_overlap=1000)\ntext_chunks = text_splitter.split_documents(data)\nlen(text_chunks)\ntext_chunks[0]\n\nvector_store = FAISS.from_documents(text_chunks, embedding=embeddings)\n\n","metadata":{"id":"A2cE1aqne1MC","papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"execution":{"iopub.status.busy":"2024-01-22T17:37:43.172310Z","iopub.execute_input":"2024-01-22T17:37:43.173196Z","iopub.status.idle":"2024-01-22T17:37:43.406614Z","shell.execute_reply.started":"2024-01-22T17:37:43.173162Z","shell.execute_reply":"2024-01-22T17:37:43.405644Z"},"trusted":true},"execution_count":71,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43e62ed65b0b441b8869d32e069840ad"}},"metadata":{}}]},{"cell_type":"markdown","source":"#тут без цикла,вводим запрос в переменную query","metadata":{"id":"CeGOr0am9q6h","papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]}},{"cell_type":"code","source":"\n\nqa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=vector_store.as_retriever(search_kwargs={\"k\": 2}))","metadata":{"id":"3QNydLoIejTs","papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"execution":{"iopub.status.busy":"2024-01-22T17:37:46.535688Z","iopub.execute_input":"2024-01-22T17:37:46.536041Z","iopub.status.idle":"2024-01-22T17:37:46.549683Z","shell.execute_reply.started":"2024-01-22T17:37:46.536014Z","shell.execute_reply":"2024-01-22T17:37:46.548848Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"query = \"О чём говорится в разговоре? \"","metadata":{"id":"UV5Ga0HY704y","papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"execution":{"iopub.status.busy":"2024-01-22T16:08:49.896189Z","iopub.execute_input":"2024-01-22T16:08:49.897094Z","iopub.status.idle":"2024-01-22T16:08:49.901298Z","shell.execute_reply.started":"2024-01-22T16:08:49.897060Z","shell.execute_reply":"2024-01-22T16:08:49.900164Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"promt_template = \"Ты мультилингвальный дружелюбный помощник, который всё знает. Выполни, что тебя просят. Если тебя попросят ответ, но ты его не знаешь, то ответ что не знаешь.\"","metadata":{"id":"cWDxUaF64anv","papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"execution":{"iopub.status.busy":"2024-01-22T16:12:12.912374Z","iopub.execute_input":"2024-01-22T16:12:12.913024Z","iopub.status.idle":"2024-01-22T16:12:12.917606Z","shell.execute_reply.started":"2024-01-22T16:12:12.912989Z","shell.execute_reply":"2024-01-22T16:12:12.916637Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"import tempfile\nimport os\nfrom pydub import AudioSegment\n\nbot = telebot.TeleBot('6507009266:AAGOY56MPIsTP7qOj8rJcAKT1a1m1WID4WI')#api telegram bot\n\n@bot.message_handler(commands=['start'])\ndef start(message):\n    bot.send_message(message.chat.id, 'Привет! Можешь спрашивать меня! Что тебя интересует?')\n\n@bot.message_handler(content_types=['text'])\ndef get_text_messages(message):\n    user_input =  message.text # Добавляем сообщение в промпт\n    bot.send_message(message.from_user.id, \"Я обрабатываю ваш запрос. Ожидайте 2-5 минут\")\n    result = qa.run(user_input) # Ответ модели\n    #prediction = GoogleTranslator(source='auto', target='ru').translate(getResponse_(message.text))\n    #message = getResponse(message.text)\n    bot.send_message(message.from_user.id, result)\n\nbot.polling(none_stop=True, interval=0)","metadata":{"id":"IrkgiE6IDAax","outputId":"1d019584-0bd1-49d3-89b7-a8b464f226d2","papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"execution":{"iopub.status.busy":"2024-01-22T16:12:15.273171Z","iopub.execute_input":"2024-01-22T16:12:15.273916Z","iopub.status.idle":"2024-01-22T16:16:34.125719Z","shell.execute_reply.started":"2024-01-22T16:12:15.273880Z","shell.execute_reply":"2024-01-22T16:16:34.124826Z"},"trusted":true},"execution_count":36,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae011263080f42e2b6a60b457043719f"}},"metadata":{}},{"name":"stderr","text":"Llama.generate: prefix-match hit\n\nllama_print_timings:        load time =    1762.07 ms\nllama_print_timings:      sample time =      15.68 ms /    29 runs   (    0.54 ms per token,  1849.73 tokens per second)\nllama_print_timings: prompt eval time =    3015.66 ms /    14 tokens (  215.40 ms per token,     4.64 tokens per second)\nllama_print_timings:        eval time =    8398.43 ms /    28 runs   (  299.94 ms per token,     3.33 tokens per second)\nllama_print_timings:       total time =   11555.36 ms /    42 tokens\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install python-telegram-bot","metadata":{"execution":{"iopub.status.busy":"2024-01-22T16:23:10.128339Z","iopub.execute_input":"2024-01-22T16:23:10.128709Z","iopub.status.idle":"2024-01-22T16:23:24.502640Z","shell.execute_reply.started":"2024-01-22T16:23:10.128679Z","shell.execute_reply":"2024-01-22T16:23:24.501488Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting python-telegram-bot\n  Downloading python_telegram_bot-20.7-py3-none-any.whl.metadata (15 kB)\nCollecting httpx~=0.25.2 (from python-telegram-bot)\n  Downloading httpx-0.25.2-py3-none-any.whl.metadata (6.9 kB)\nRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx~=0.25.2->python-telegram-bot) (3.7.1)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx~=0.25.2->python-telegram-bot) (2023.11.17)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx~=0.25.2->python-telegram-bot) (1.0.2)\nRequirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx~=0.25.2->python-telegram-bot) (3.4)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx~=0.25.2->python-telegram-bot) (1.3.0)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx~=0.25.2->python-telegram-bot) (0.14.0)\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio->httpx~=0.25.2->python-telegram-bot) (1.1.3)\nDownloading python_telegram_bot-20.7-py3-none-any.whl (552 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m552.6/552.6 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading httpx-0.25.2-py3-none-any.whl (74 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: httpx, python-telegram-bot\n  Attempting uninstall: httpx\n    Found existing installation: httpx 0.26.0\n    Uninstalling httpx-0.26.0:\n      Successfully uninstalled httpx-0.26.0\nSuccessfully installed httpx-0.25.2 python-telegram-bot-20.7\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import tempfile\nimport os\nimport subprocess\nfrom pydub import AudioSegment\nimport subprocess\nimport contextlib\nimport wave\nimport numpy as np\nfrom pydub import AudioSegment\nfrom sklearn.cluster import AgglomerativeClustering\nimport datetime\nfrom reportlab.lib.pagesizes import letter\n\nfrom reportlab.pdfbase import pdfmetrics\nfrom reportlab.pdfbase.ttfonts import TTFont\nfrom reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer\nfrom reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n\nbot = telebot.TeleBot('6507009266:AAGOY56MPIsTP7qOj8rJcAKT1a1m1WID4WI')  # ваш API-ключ для Telegram Bot\n\n@bot.message_handler(commands=['start'])\ndef start(message):\n    bot.send_message(message.chat.id, 'Привет! Можешь спрашивать меня! Что тебя интересует?')\n\n@bot.message_handler(content_types=['text', 'audio'])\ndef handle_messages(message):\n    if message.content_type == 'text':\n        user_input = message.text\n        bot.send_message(message.from_user.id, \"Я обрабатываю ваш запрос. Ожидайте 2-5 минут\")\n        loader = PyPDFDirectoryLoader(\"/kaggle/working/\")\n        data = loader.load()\n\n        embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n\n        text_splitter = RecursiveCharacterTextSplitter(chunk_size=5000, chunk_overlap=1000)\n        text_chunks = text_splitter.split_documents(data)\n\n        vector_store = FAISS.from_documents(text_chunks, embedding=embeddings)\n        qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=vector_store.as_retriever(search_kwargs={\"k\": 2}))\n        result = qa.run(user_input)\n        bot.send_message(message.from_user.id, result)\n    elif message.content_type == 'audio':\n        # Сохраняем аудиофайл, чтобы обработать его\n        file_id = message.audio.file_id\n        file_info = bot.get_file(file_id)\n        downloaded_file = bot.download_file(file_info.file_path)\n        temp_file_path = \"/kaggle/working/audio_input.ogg\"  # Выберите формат, поддерживаемый pydub\n        with open(temp_file_path, 'wb') as new_file:\n            new_file.write(downloaded_file)\n\n        # Обрабатываем аудиофайл\n        result = process_audio(temp_file_path)\n        bot.send_message(message.from_user.id, result)\n\n\n# Функция для обработки аудиофайла\ndef process_audio(audio_path):\n    if audio_path[-3:] != 'wav':\n        subprocess.call(['ffmpeg', '-i', audio_path, 'audio.wav', '-y'])\n        audio_path = 'audio.wav'\n\n    result = model.transcribe(audio_path)\n    segments = result[\"segments\"]\n\n    with contextlib.closing(wave.open(audio_path, 'r')) as f:\n        frames = f.getnframes()\n        rate = f.getframerate()\n        duration = frames / float(rate)\n\n    audio = Audio()\n\n    def segment_embedding(segment):\n        start = segment[\"start\"]\n        end = min(duration, segment[\"end\"])\n        clip = Segment(start, end)\n        waveform, sample_rate = audio.crop(audio_path, clip)\n        return embedding_model(waveform[None])\n\n    embeddings1 = np.zeros(shape=(len(segments), 192))\n    for i, segment in enumerate(segments):\n        embeddings1[i] = segment_embedding(segment)\n\n    embeddings1 = np.nan_to_num(embeddings1)\n\n    clustering = AgglomerativeClustering(num_speakers).fit(embeddings1)\n    labels = clustering.labels_\n    for i in range(len(segments)):\n        segments[i][\"speaker\"] = 'SPEAKER ' + str(labels[i] + 1)\n\n    def time(secs):\n        return datetime.timedelta(seconds=round(secs))\n\n    transcript_content = \"\"\n    for (i, segment) in enumerate(segments):\n        if i == 0 or segments[i - 1][\"speaker\"] != segment[\"speaker\"]:\n            transcript_content += \"\\n\" + segment[\"speaker\"] + ' ' + str(time(segment[\"start\"])) + '\\n'\n        transcript_content += segment[\"text\"][1:] + ' '\n\n    transcript_file_path = \"/kaggle/working/transcript.txt\"\n    with open(transcript_file_path, \"w\") as f:\n        f.write(transcript_content)\n\n    # Конвертация текстового файла в PDF\n    font_path = '/kaggle/input/dejfont/DejaVuSans.ttf'\n    pdfmetrics.registerFont(TTFont(\"DejaVu\", font_path))\n\n    styles = getSampleStyleSheet()\n    custom_style = ParagraphStyle(\n        'CustomStyle',\n        parent=styles['Normal'],\n        fontName='DejaVu',\n        fontSize=12,\n    )\n\n    pdf_file_path = \"/kaggle/working/transcript.pdf\"\n    create_pdf(transcript_file_path, pdf_file_path)\n\n    return \"Аудиофайл успешно обработан. Транскрипция сохранена в transcript.txt, а PDF-файл в transcript.pdf\"\n\nbot.polling(none_stop=True, interval=0)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-22T18:25:03.581289Z","iopub.execute_input":"2024-01-22T18:25:03.581646Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n  libavutil      56. 70.100 / 56. 70.100\n  libavcodec     58.134.100 / 58.134.100\n  libavformat    58. 76.100 / 58. 76.100\n  libavdevice    58. 13.100 / 58. 13.100\n  libavfilter     7.110.100 /  7.110.100\n  libswscale      5.  9.100 /  5.  9.100\n  libswresample   3.  9.100 /  3.  9.100\n  libpostproc    55.  9.100 / 55.  9.100\n[mp3 @ 0x5cc5d949e540] Estimating duration from bitrate, this may be inaccurate\nInput #0, mp3, from '/kaggle/working/audio_input.ogg':\n  Duration: 00:01:18.07, start: 0.000000, bitrate: 23 kb/s\n  Stream #0:0: Audio: mp3, 16000 Hz, mono, fltp, 24 kb/s\nStream mapping:\n  Stream #0:0 -> #0:0 (mp3 (mp3float) -> pcm_s16le (native))\nPress [q] to stop, [?] for help\nOutput #0, wav, to 'audio.wav':\n  Metadata:\n    ISFT            : Lavf58.76.100\n  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n    Metadata:\n      encoder         : Lavc58.134.100 pcm_s16le\nsize=    2440kB time=00:01:18.04 bitrate= 256.1kbits/s speed= 777x    \nvideo:0kB audio:2440kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.003122%\nffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n  libavutil      56. 70.100 / 56. 70.100\n  libavcodec     58.134.100 / 58.134.100\n  libavformat    58. 76.100 / 58. 76.100\n  libavdevice    58. 13.100 / 58. 13.100\n  libavfilter     7.110.100 /  7.110.100\n  libswscale      5.  9.100 /  5.  9.100\n  libswresample   3.  9.100 /  3.  9.100\n  libpostproc    55.  9.100 / 55.  9.100\nInput #0, mp3, from '/kaggle/working/audio_input.ogg':\n  Duration: 00:04:18.36, start: 0.023021, bitrate: 91 kb/s\n  Stream #0:0: Audio: mp3, 48000 Hz, mono, fltp, 91 kb/s\n    Metadata:\n      encoder         : LAME3.100\nStream mapping:\n  Stream #0:0 -> #0:0 (mp3 (mp3float) -> pcm_s16le (native))\nPress [q] to stop, [?] for help\nOutput #0, wav, to 'audio.wav':\n  Metadata:\n    ISFT            : Lavf58.76.100\n  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 48000 Hz, mono, s16, 768 kb/s\n    Metadata:\n      encoder         : Lavc58.134.100 pcm_s16le\nsize=   24217kB time=00:04:18.31 bitrate= 768.0kbits/s speed= 719x    \nvideo:0kB audio:24217kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.000315%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dbab878086a343ec97054c5eda22b0a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64b947e3c3704f4d9a51b41908edb859"}},"metadata":{}},{"name":"stderr","text":"Llama.generate: prefix-match hit\n\nllama_print_timings:        load time =    1762.07 ms\nllama_print_timings:      sample time =      19.67 ms /    34 runs   (    0.58 ms per token,  1728.43 tokens per second)\nllama_print_timings: prompt eval time =  248918.33 ms /  1164 tokens (  213.85 ms per token,     4.68 tokens per second)\nllama_print_timings:        eval time =   10465.66 ms /    33 runs   (  317.14 ms per token,     3.15 tokens per second)\nllama_print_timings:       total time =  260110.97 ms /  1197 tokens\nffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n  libavutil      56. 70.100 / 56. 70.100\n  libavcodec     58.134.100 / 58.134.100\n  libavformat    58. 76.100 / 58. 76.100\n  libavdevice    58. 13.100 / 58. 13.100\n  libavfilter     7.110.100 /  7.110.100\n  libswscale      5.  9.100 /  5.  9.100\n  libswresample   3.  9.100 /  3.  9.100\n  libpostproc    55.  9.100 / 55.  9.100\n[mp3 @ 0x5a51924b7540] Estimating duration from bitrate, this may be inaccurate\nInput #0, mp3, from '/kaggle/working/audio_input.ogg':\n  Duration: 00:01:18.07, start: 0.000000, bitrate: 23 kb/s\n  Stream #0:0: Audio: mp3, 16000 Hz, mono, fltp, 24 kb/s\nStream mapping:\n  Stream #0:0 -> #0:0 (mp3 (mp3float) -> pcm_s16le (native))\nPress [q] to stop, [?] for help\nOutput #0, wav, to 'audio.wav':\n  Metadata:\n    ISFT            : Lavf58.76.100\n  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n    Metadata:\n      encoder         : Lavc58.134.100 pcm_s16le\nsize=    2440kB time=00:01:18.04 bitrate= 256.1kbits/s speed= 788x    \nvideo:0kB audio:2440kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.003122%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c52d2fe9b9124a0bbb1c1315fbd2379a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2663f8cf49b847a29f93bfc637309f8a"}},"metadata":{}},{"name":"stderr","text":"Llama.generate: prefix-match hit\n\nllama_print_timings:        load time =    1762.07 ms\nllama_print_timings:      sample time =      31.97 ms /    57 runs   (    0.56 ms per token,  1782.81 tokens per second)\nllama_print_timings: prompt eval time =  149957.54 ms /   711 tokens (  210.91 ms per token,     4.74 tokens per second)\nllama_print_timings:        eval time =   16811.83 ms /    56 runs   (  300.21 ms per token,     3.33 tokens per second)\nllama_print_timings:       total time =  167395.19 ms /   767 tokens\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}